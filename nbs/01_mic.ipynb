{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp mic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mic streaming and recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import io\n",
    "import sys \n",
    "import queue\n",
    "\n",
    "import zmq\n",
    "import fire\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from asr_teach.utils import SAMPLE_RATE, DEVICE, BLOCK_DURATION, DTYPE\n",
    "from asr_teach.utils import ZMQ_ARGS, PROTOCOL, ADDR, PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AudioStream:\n",
    "    def __init__(self,\n",
    "                 sample_rate: float = None,\n",
    "                 device: int = 0,\n",
    "                 dtype: str = DTYPE,\n",
    "                 addr: str = ADDR,\n",
    "                 port: int = PORT,\n",
    "                 protocol: str = PROTOCOL):\n",
    "        store_attr()\n",
    "        \n",
    "        # create the socket\n",
    "        context = zmq.Context()\n",
    "        socket = context.socket(zmq.PUSH)\n",
    "        socket.bind(f'{protocol}://{addr}:{port}')\n",
    "        self.socket = socket\n",
    "        \n",
    "        # queue to hold live mic data\n",
    "        self.q = queue.Queue()\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def setup_stream(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def send_audio(self, indata, flags=0, copy=True, track=False):\n",
    "        '''Sends a numpy array in a multi-part message.\n",
    "        \n",
    "        The first part of the message has the shape and type of the array.\n",
    "        The second message has the raw array bytes. \n",
    "        '''\n",
    "        # send the array info\n",
    "        md = {'dtype': str(indata.dtype),\n",
    "              'shape': indata.shape}\n",
    "        self.socket.send_json(md, zmq.SNDMORE)\n",
    "        # sends the array data\n",
    "        self.socket.send(indata, flags, copy=copy, track=track)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SoundDeviceMic(AudioStream):\n",
    "    def __init__(self, *args,\n",
    "                 block_duration: int = 2500,\n",
    "                 **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        store_attr()\n",
    "        self.setup_stream()\n",
    "        \n",
    "    def setup_stream(self):\n",
    "        \n",
    "        # setting the sample rate and mic buffer size\n",
    "        self.sample_rate = self.sample_rate or sd.query_devices(self.device, 'input')['default_samplerate']\n",
    "        self.num_samples = int(self.sample_rate * self.block_duration)\n",
    "        self.blocksize = self.num_samples // 1000\n",
    "\n",
    "        def enqueue_audio(indata, frames, time, status):\n",
    "            '''Places audio data on the queue.\n",
    "            '''\n",
    "            if any(indata):\n",
    "                self.q.put(indata)\n",
    "        \n",
    "        # create the microphone streaming object\n",
    "        self.stream = sd.InputStream(device=self.device,\n",
    "                                     channels=1,\n",
    "                                     callback=enqueue_audio,\n",
    "                                     dtype=self.dtype,\n",
    "                                     blocksize=self.blocksize,\n",
    "                                     samplerate=self.sample_rate)\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        '''Streams audio until the user stops or interrupts the process.\n",
    "        '''\n",
    "        # start the microphone stream\n",
    "        self.stream.start()\n",
    "        print('Streaming live mic audio...')\n",
    "        while True:\n",
    "            try:\n",
    "                # send any audio on the queue\n",
    "                if not self.q.empty():\n",
    "                    self.send_audio(self.q.get())\n",
    "                    \n",
    "            except KeyboardInterrupt:\n",
    "                print('User keyboard interrupt, stopping mic...')\n",
    "                self.stream.close()\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'Exception: {e}')\n",
    "                raise\n",
    "                \n",
    "        print('Live mic stopped.')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microphone streaming via the SpeechRecognition repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SpeechRecogMic(AudioStream):\n",
    "    def __init__(self, *args,\n",
    "                 energy: int = 500,\n",
    "                 pause: float = 0.8,\n",
    "                 dynamic_energy: bool = False,\n",
    "                 **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        store_attr()\n",
    "        self.setup_stream()\n",
    "        \n",
    "    def setup_stream(self):\n",
    "        \n",
    "        # load the speech recognizer with CLI settings\n",
    "        recog = sr.Recognizer()\n",
    "        recog.energy_threshold = self.energy\n",
    "        recog.pause_threshold = self.pause\n",
    "        recog.dynamic_energy_threshold = self.dynamic_energy\n",
    "        self.recog = recog\n",
    "        \n",
    "        self.mic = sr.Microphone(device_index=self.device,\n",
    "                                 sample_rate=self.sample_rate)\n",
    "\n",
    "    def run(self):\n",
    "        with self.mic as source:\n",
    "            print(\"Starting mic stream...\")\n",
    "            while True:\n",
    "                # record audio stream into wav\n",
    "                try:\n",
    "                    data = self.recog.listen(source)\n",
    "                    audio = np.frombuffer(data.frame_data, dtype=np.int16)\n",
    "                    audio = audio.flatten().astype(np.float32) / 32768.0\n",
    "                    self.send_audio(audio)\n",
    "                    \n",
    "                except KeyboardInterrupt:\n",
    "                    print('User keyboard interrupt, stopping mic...')\n",
    "                    break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Exception: {e}')\n",
    "                    raise\n",
    "            print('Mic stopped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def stream(sample_rate: float = SAMPLE_RATE,\n",
    "           device: int = DEVICE,\n",
    "           block_duration: int = BLOCK_DURATION,\n",
    "           **kwargs):\n",
    "    '''Entrypoint for live microphone streaming over a port.\n",
    "    '''\n",
    "    # create and start the microphone stream\n",
    "    mic = MicStream(sample_rate, device, block_duration, **kwargs)\n",
    "    mic.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
