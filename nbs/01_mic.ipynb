{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp mic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming live audio from a microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes to stream audio from a microphone. Live audio is sent over a ZMQ port for further processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the needed python libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import io\n",
    "import sys \n",
    "import queue\n",
    "\n",
    "import zmq\n",
    "import fire\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import some default values from the `asr_teach.utils` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from asr_teach.utils import SAMPLE_RATE, DEVICE, BLOCK_DURATION, DTYPE\n",
    "from asr_teach.utils import ZMQ_ARGS, PROTOCOL, ADDR, PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base `AudioStream` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AudioStream` class implements the basic, shared functionality to stream live audio from a mic. It takes the following arguments:  \n",
    "\n",
    "- sample_rate: The sampling rate for the microphone audio.  \n",
    "- device: The hardware ID of the microphone. Will often be `0` or `1` depending on the setup.  \n",
    "- dtype: Data type for the recorded audio. Most microphone record  audio as Short Ints (16 bits aka `np.int16`).  \n",
    "- protocol: The transport protocol for the ZMQ port (default: TCP).  \n",
    "- addr: The address (typically an IP address) for the ZMQ connection.  \n",
    "- port: The specific port that audio will be sent over.  \n",
    "\n",
    "The class creates a ZMQ socket to carry the output audio samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AudioStream:\n",
    "    def __init__(self,\n",
    "                 sample_rate: float = None,\n",
    "                 device: int = 0,\n",
    "                 dtype: str = DTYPE,\n",
    "                 addr: str = ADDR,\n",
    "                 port: int = PORT,\n",
    "                 protocol: str = PROTOCOL):\n",
    "        \"\"\"Base audio stream class.\n",
    "        \"\"\"\n",
    "        store_attr()\n",
    "        \n",
    "        # creates the ZMQ socket\n",
    "        context = zmq.Context()\n",
    "        socket = context.socket(zmq.PUSH)\n",
    "        socket.bind(f'{protocol}://{addr}:{port}')\n",
    "        self.socket = socket\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Runs the microphone streaming.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def setup_stream(self):\n",
    "        \"\"\"Initializes and sets up a specific stream.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def send_audio(self, indata, flags=0, copy=True, track=False):\n",
    "        '''Sends a numpy array as a multi-part message.\n",
    "    \n",
    "        The first part of the message has the shape and type of the array.\n",
    "        The second message has the raw array bytes.\n",
    "        Both pieces of information are needed to correctly deserialize the array at the receiver. \n",
    "        '''\n",
    "        # sends the array's shape and type info\n",
    "        md = {'dtype': str(indata.dtype),\n",
    "              'shape': indata.shape}\n",
    "        self.socket.send_json(md, zmq.SNDMORE)\n",
    "        # sends the raw array bytes\n",
    "        self.socket.send(indata, flags, copy=copy, track=track)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming via the `sounddevice` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SoundDeviceMic` class uses the `sounddevice` python library to stream continuous audio from a microphone. \n",
    "\n",
    "The `block_duration`, given in milliseconds, determines the size of the recorded audio buffer. For example if `block_duration = 2500` then 2500 milliseconds (aka 2.5 seconds) of audio will be buffered in and made ready for processing.    \n",
    "\n",
    "The `sounddevice` library records audio in a separate thread, and we can process these buffered samples from our main thread via a `callback` function. In our case, the callback function places the audio samples on a queue. We then pop samples from the queue and send them over the ZMQ socket.  \n",
    "\n",
    "We use a queue as a middleman because the `sounddevice` library makes a few strong assumptions about the callback. In summary, the callback needs to be as fast as possible so that it does not block the audio stream in the separate thread. This means we should avoid IO and network calls from the callback itself. For this reason our callback simply places audio samples on the queue and allows the separate thread to continue at will. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SoundDeviceMic(AudioStream):\n",
    "    def __init__(self, *args,\n",
    "                 block_duration: int = 2500,\n",
    "                 **kwargs):\n",
    "        '''Streams continuous live audio with the `sounddevice` library.\n",
    "        '''\n",
    "        super().__init__(*args, **kwargs)\n",
    "        store_attr()\n",
    "        self.setup_stream()\n",
    "        \n",
    "    def setup_stream(self):\n",
    "        '''Prepares the `sounddevice` stream.\n",
    "        \n",
    "        First, we figure out the sampling rate and audio buffer sizes.\n",
    "        Next we initialize a queue for the buffered audio samples.\n",
    "        \n",
    "        Lastly, we create the microphone stream with the callback that processes the recorded audio.\n",
    "        '''\n",
    "        \n",
    "        # setting the sample rate and mic buffer size\n",
    "        self.sample_rate = self.sample_rate or sd.query_devices(self.device, 'input')['default_samplerate']\n",
    "        self.num_samples = int(self.sample_rate * self.block_duration)\n",
    "        self.blocksize = self.num_samples // 1000\n",
    "        \n",
    "        # queue to hold the mic data\n",
    "        self.q = queue.Queue()\n",
    "\n",
    "        def enqueue_audio(indata, frames, time, status):\n",
    "            '''Places buffered audio data on the queue.\n",
    "            '''\n",
    "            if any(indata):\n",
    "                self.q.put(indata)\n",
    "        \n",
    "        # create the microphone streaming object\n",
    "        self.stream = sd.InputStream(device=self.device,\n",
    "                                     channels=1,\n",
    "                                     callback=enqueue_audio,\n",
    "                                     dtype=self.dtype,\n",
    "                                     blocksize=self.blocksize,\n",
    "                                     samplerate=self.sample_rate)\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        '''Streams audio until the user stops or interrupts the process.\n",
    "        \n",
    "        We continuously check whether there are any audio samples on the queue.\n",
    "        If there are, we send them over the ZMQ socket.  \n",
    "        '''\n",
    "        # start the microphone stream\n",
    "        self.stream.start()\n",
    "        print('Streaming live mic audio...')\n",
    "        \n",
    "        while True:\n",
    "            # send any audio on the queue\n",
    "            try:\n",
    "                if not self.q.empty():\n",
    "                    self.send_audio(self.q.get())\n",
    "                    \n",
    "            except KeyboardInterrupt:\n",
    "                print('User keyboard interrupt, stopping mic...')\n",
    "                self.stream.close()\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'Exception: {e}')\n",
    "                raise\n",
    "                \n",
    "        print('Live mic stopped.')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming via the `SpeechRecognition` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SpeechRecogMic` is a more advanced audio stream using the `SpeechRecognition` library.  \n",
    "\n",
    "This stream takes a few arguments to run energy detection on the microphone. Instead of continuously streaming potentially empty audio, this class only records and sends audio when the microphone activity crosses a certain energy threshold.  \n",
    "\n",
    "The stream will wait and hold until the energy threshold is crossed.  \n",
    "\n",
    "Then, it waits for the user to stop speaking before stopping the recording and sending the audio over. The wait time for a recording to be over is set via the `pause` argument.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SpeechRecogMic(AudioStream):\n",
    "    def __init__(self, *args,\n",
    "                 energy: int = 500,\n",
    "                 pause: float = 0.8,\n",
    "                 dynamic_energy: bool = False,\n",
    "                 **kwargs):\n",
    "        '''Streams microphone audio with the SoundRecognizer library.\n",
    "        '''\n",
    "        super().__init__(*args, **kwargs)\n",
    "        store_attr()\n",
    "        self.setup_stream()\n",
    "        \n",
    "    def setup_stream(self):\n",
    "        '''Creates the energy-aware speech recognizer and microphone stream.\n",
    "        '''\n",
    "        \n",
    "        # loads the speech recognizer with energy and pause parameters\n",
    "        recog = sr.Recognizer()\n",
    "        recog.energy_threshold = self.energy\n",
    "        recog.pause_threshold = self.pause\n",
    "        recog.dynamic_energy_threshold = self.dynamic_energy\n",
    "        self.recog = recog\n",
    "        \n",
    "        # initializes the chosen microphone stream\n",
    "        self.mic = sr.Microphone(device_index=self.device,\n",
    "                                 sample_rate=self.sample_rate)\n",
    "\n",
    "    def run(self):\n",
    "        '''Streams audio until the user stops or interrupts the process.\n",
    "        \n",
    "        The recognizer `recog` starts recording once the microphone's energy  \n",
    "        crosses the threshold. Then, it keeps recording until the energy drops\n",
    "        for `pause` seconds.  \n",
    "        \n",
    "        The raw buffer bytes are then cast as a numpy short-int array and sent\n",
    "        over the ZMQ port.\n",
    "        '''\n",
    "        with self.mic as source:\n",
    "            print(\"Starting mic stream...\")\n",
    "            \n",
    "            while True:\n",
    "                # record audio stream into wav\n",
    "                try:\n",
    "                    data = self.recog.listen(source)\n",
    "                    audio = np.frombuffer(data.frame_data, dtype=np.int16)\n",
    "                    #audio = audio.flatten().astype(np.float32) / 32768.0\n",
    "                    self.send_audio(audio)\n",
    "                    \n",
    "                except KeyboardInterrupt:\n",
    "                    print('User keyboard interrupt, stopping mic...')\n",
    "                    break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Exception: {e}')\n",
    "                    raise\n",
    "                    \n",
    "            print('Mic stopped.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
